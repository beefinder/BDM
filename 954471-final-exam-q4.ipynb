{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"| ![image.png](attachment:68c7e366-9d45-47ff-838c-0c1c38dc08cb.png) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;          |        <em><font size=5>Department of Modern Management and <br> Information Technology </font></em><br>  <font size=3>College of Arts, Media and Technology,<br> Chiang Mai University<br></font> Midterm Examination, Academic Year 2021 <br> Business Data Mining 954471\n|:- |-: \n|<strong> ctober 18th, 2021 8:00 - 23:59 </strong>| <strong>(Total 35 Points) </strong>\n\n<b>Name_________________Namphueng__Auawatcharo__________ Student ID_________622110186___________________________</b>\n\nInstructions: \n\n-\tThis exam is worth 35% of your final grade.\n-\tThis exam consists of 5 Questions\n-\tFinish this exam, download it as .ipynb file and send it to my FB messenger.\n-\tWrite your student ID as filename. \n-\tAllow anything.\n-\t<b>Please do this exam alone and be honest to yourself. </b>\n-\tThe time allowed students to leave the testing room after the exam is open to copy it.\n-\tStudents who cheat in any way will be prosecuted by the CMU regulation BE 2554, which governs student behavior and describes discipline during the exam period. The proctor must report any suspected cheating to the director.\n<br>\n\n### <em>Score Sheet:</em>\n|<font size=3> Question|<font size=3> Full Mark|<font size=3> Student’s Mark|\n|:- |:-:|:-:\n<font size=3> Q4 |<font size=3> 10|\n<font size=3> Total|<font size=3> 10|\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:30:56.332805Z","iopub.execute_input":"2021-10-18T10:30:56.333720Z","iopub.status.idle":"2021-10-18T10:30:56.338126Z","shell.execute_reply.started":"2021-10-18T10:30:56.333677Z","shell.execute_reply":"2021-10-18T10:30:56.337241Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:30:56.340324Z","iopub.execute_input":"2021-10-18T10:30:56.340847Z","iopub.status.idle":"2021-10-18T10:30:56.705320Z","shell.execute_reply.started":"2021-10-18T10:30:56.340808Z","shell.execute_reply":"2021-10-18T10:30:56.704502Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# **Q4**\n#### From this food images (\"../input/food41/images\"), please create an image classifier to classify 2 types of food choosing by yourself. (Show me the accuracy of each type of food) \n<b><font color=red>Both types of food must be more than 50% to get full score.</font></b>","metadata":{}},{"cell_type":"markdown","source":"# **Preprocessing**","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/food41/images*","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:30:56.706556Z","iopub.execute_input":"2021-10-18T10:30:56.706814Z","iopub.status.idle":"2021-10-18T10:30:57.481097Z","shell.execute_reply.started":"2021-10-18T10:30:56.706783Z","shell.execute_reply":"2021-10-18T10:30:57.480086Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"!mkdir train\n!mkdir train/donuts\n!mkdir train/steak","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:30:57.485978Z","iopub.execute_input":"2021-10-18T10:30:57.486352Z","iopub.status.idle":"2021-10-18T10:30:59.619683Z","shell.execute_reply.started":"2021-10-18T10:30:57.486313Z","shell.execute_reply":"2021-10-18T10:30:59.618812Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"!mkdir test\n!mkdir test/donuts\n!mkdir test/steak","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:30:59.623018Z","iopub.execute_input":"2021-10-18T10:30:59.623246Z","iopub.status.idle":"2021-10-18T10:31:01.719780Z","shell.execute_reply.started":"2021-10-18T10:30:59.623217Z","shell.execute_reply":"2021-10-18T10:31:01.718719Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"**TRAIN**","metadata":{}},{"cell_type":"code","source":"import glob \ndonutsfile = np.array(glob.glob(\"/kaggle/input/food41/images/donuts/*.*\"))\nsteakfile = np.array(glob.glob(\"/kaggle/input/food41/images/steak/*.*\"))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:01.723206Z","iopub.execute_input":"2021-10-18T10:31:01.723473Z","iopub.status.idle":"2021-10-18T10:31:01.739679Z","shell.execute_reply.started":"2021-10-18T10:31:01.723430Z","shell.execute_reply":"2021-10-18T10:31:01.738707Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"donuts = np.array([int(item.split(\"/\")[-1].split(\".\")[0]) for item in donutsfile])\nsteak = np.array([int(item.split(\"/\")[-1].split(\".\")[0]) for item in steakfile])","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:01.741575Z","iopub.execute_input":"2021-10-18T10:31:01.742226Z","iopub.status.idle":"2021-10-18T10:31:01.751446Z","shell.execute_reply.started":"2021-10-18T10:31:01.742191Z","shell.execute_reply":"2021-10-18T10:31:01.750691Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import shutil\nfor i in range(len(donuts)-200):\n    shutil.copy(donutsfile[i], '/kaggle/working/train/donuts/')\nfor i in range(len(steak)-200):\n    shutil.copy(steakfile[i], '/kaggle/working/train/steak/')","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:01.752963Z","iopub.execute_input":"2021-10-18T10:31:01.753467Z","iopub.status.idle":"2021-10-18T10:31:03.434494Z","shell.execute_reply.started":"2021-10-18T10:31:01.753430Z","shell.execute_reply":"2021-10-18T10:31:03.433591Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"**TEST**","metadata":{}},{"cell_type":"code","source":"for i in range(800,len(donuts)):\n    shutil.copy(donutsfile[i],'/kaggle/working/test/donuts')\nfor i in range(800,len(steak)):\n    shutil.copy(steakfile[i],'/kaggle/working/test/steak')","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:03.440887Z","iopub.execute_input":"2021-10-18T10:31:03.441229Z","iopub.status.idle":"2021-10-18T10:31:03.816906Z","shell.execute_reply.started":"2021-10-18T10:31:03.441193Z","shell.execute_reply":"2021-10-18T10:31:03.816026Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working/train/donuts/* | wc -l","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:03.818329Z","iopub.execute_input":"2021-10-18T10:31:03.818576Z","iopub.status.idle":"2021-10-18T10:31:04.535594Z","shell.execute_reply.started":"2021-10-18T10:31:03.818542Z","shell.execute_reply":"2021-10-18T10:31:04.534663Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working/train/steak/* | wc -l","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:04.539127Z","iopub.execute_input":"2021-10-18T10:31:04.539371Z","iopub.status.idle":"2021-10-18T10:31:05.272286Z","shell.execute_reply.started":"2021-10-18T10:31:04.539342Z","shell.execute_reply":"2021-10-18T10:31:05.271452Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working/test/donuts/* | wc -l","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:05.273839Z","iopub.execute_input":"2021-10-18T10:31:05.274594Z","iopub.status.idle":"2021-10-18T10:31:05.973761Z","shell.execute_reply.started":"2021-10-18T10:31:05.274550Z","shell.execute_reply":"2021-10-18T10:31:05.972977Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working/test/steak/* | wc -l","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:05.976769Z","iopub.execute_input":"2021-10-18T10:31:05.976999Z","iopub.status.idle":"2021-10-18T10:31:06.686431Z","shell.execute_reply.started":"2021-10-18T10:31:05.976971Z","shell.execute_reply":"2021-10-18T10:31:06.685560Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# **CNN**","metadata":{}},{"cell_type":"code","source":"#Images Augumentation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ndata_generator = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        #rescale = 1.0/255.0,   # Intensity Normalized\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180) #หมุนภาพ\n        zoom_range = 0.2, # Randomly zoom image #ซูมภาพ\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False,   # randomly flip images\n        validation_split=0.2) #แบ่่ง validation ไปใช้ใน deep learning ","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:06.689794Z","iopub.execute_input":"2021-10-18T10:31:06.690091Z","iopub.status.idle":"2021-10-18T10:31:06.696822Z","shell.execute_reply.started":"2021-10-18T10:31:06.690055Z","shell.execute_reply":"2021-10-18T10:31:06.695909Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"#data generator\nbatch_size = 35\nimg_height = 100 \nimg_width  = 100 \ntrain_dir = './train'\n\n#train set\ntrain_generator = data_generator.flow_from_directory(\n    train_dir ,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary', # label มีสองกลุ่มคือ dog กับ cat\n    subset='training') # set as training data\n\n#validation set\nvalidation_generator = data_generator.flow_from_directory(\n    train_dir, # same directory as training data\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary', # label มีสองกลุ่มคือ dog กับ cat\n    subset='validation') # set as validation data","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:06.698011Z","iopub.execute_input":"2021-10-18T10:31:06.698691Z","iopub.status.idle":"2021-10-18T10:31:06.917776Z","shell.execute_reply.started":"2021-10-18T10:31:06.698658Z","shell.execute_reply":"2021-10-18T10:31:06.917099Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train_generator.class_indices","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:06.919019Z","iopub.execute_input":"2021-10-18T10:31:06.919275Z","iopub.status.idle":"2021-10-18T10:31:06.926055Z","shell.execute_reply.started":"2021-10-18T10:31:06.919231Z","shell.execute_reply":"2021-10-18T10:31:06.925251Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n# preparing the layers in the Convolutional Deep Neural Network\n\ndef create_model():\n    tf.random.set_seed(0)\n    tf.compat.v1.reset_default_graph() # Clear Model\n    #แบ่ง layers \n    model = Sequential()\n    model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation = 'relu', input_shape = train_generator.image_shape)) #32 kernal ขนาด 3x3\n    model.add(MaxPooling2D(pool_size = (2, 2))) \n    model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    model.add(Dropout(rate = 0.2))\n    \n    model.add(Flatten()) \n    \n    model.add(Dense(units = 16, activation = 'relu'))\n    model.add(Dense(units = 32, activation = 'relu'))\n    model.add(Dense(units = 32, activation = 'relu'))\n    model.add(Dense(units = 1, activation = 'sigmoid'))\n    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:06.927828Z","iopub.execute_input":"2021-10-18T10:31:06.928111Z","iopub.status.idle":"2021-10-18T10:31:06.940991Z","shell.execute_reply.started":"2021-10-18T10:31:06.928079Z","shell.execute_reply":"2021-10-18T10:31:06.940321Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nfitted_model = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples // batch_size,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples // batch_size,\n    epochs = 150)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:31:06.942201Z","iopub.execute_input":"2021-10-18T10:31:06.942537Z","iopub.status.idle":"2021-10-18T10:54:41.027357Z","shell.execute_reply.started":"2021-10-18T10:31:06.942503Z","shell.execute_reply":"2021-10-18T10:54:41.026614Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# plotting accuracy and validation accuracy\naccuracy = fitted_model.history['accuracy']\nval_accuracy = fitted_model.history['val_accuracy']\nplt.plot(range(len(accuracy)), accuracy, 'b-', label = 'accuracy')\nplt.plot(range(len(val_accuracy)), val_accuracy, 'r-', label = 'val_accuracy')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T11:00:19.899942Z","iopub.execute_input":"2021-10-18T11:00:19.900344Z","iopub.status.idle":"2021-10-18T11:00:20.139793Z","shell.execute_reply.started":"2021-10-18T11:00:19.900311Z","shell.execute_reply":"2021-10-18T11:00:20.138962Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"import glob \nfiledonuts = glob.glob(\"/kaggle/working/test/donuts/*.jpg\")\nfilesteak = glob.glob(\"/kaggle/working/test/steak/*.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-10-18T11:00:23.573240Z","iopub.execute_input":"2021-10-18T11:00:23.573794Z","iopub.status.idle":"2021-10-18T11:00:23.580632Z","shell.execute_reply.started":"2021-10-18T11:00:23.573758Z","shell.execute_reply":"2021-10-18T11:00:23.579845Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"**Donuts Prediction**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\n# testing the model\np_donuts = []\nfor filename in filedonuts:\n    test_image = image.load_img(filename, target_size = (img_height, img_width))\n    test_image = image.img_to_array(test_image)\n    test_image = np.expand_dims(test_image, axis = 0)\n    p_donuts.append(np.round(model.predict(test_image)[0][0]))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T11:00:26.132100Z","iopub.execute_input":"2021-10-18T11:00:26.132623Z","iopub.status.idle":"2021-10-18T11:00:32.756054Z","shell.execute_reply.started":"2021-10-18T11:00:26.132587Z","shell.execute_reply":"2021-10-18T11:00:32.755328Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"#donuts accuracy\np_donuts = np.array(p_donuts)\nsum(p_donuts==0)/len(p_donuts)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T11:00:32.757729Z","iopub.execute_input":"2021-10-18T11:00:32.758014Z","iopub.status.idle":"2021-10-18T11:00:32.766350Z","shell.execute_reply.started":"2021-10-18T11:00:32.757978Z","shell.execute_reply":"2021-10-18T11:00:32.765546Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"**Steak Prediction**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\n# testing the model\np_steak = []\nfor filename in filesteak:\n    test_image = image.load_img(filename, target_size = (img_height, img_width))\n    test_image = image.img_to_array(test_image)\n    test_image = np.expand_dims(test_image, axis = 0)\n    p_steak.append(np.round(model.predict(test_image)[0][0]))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T11:00:32.767764Z","iopub.execute_input":"2021-10-18T11:00:32.768099Z","iopub.status.idle":"2021-10-18T11:00:39.351809Z","shell.execute_reply.started":"2021-10-18T11:00:32.768065Z","shell.execute_reply":"2021-10-18T11:00:39.350921Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#steak accuracy\np_steak = np.array(p_steak)\nsum(p_steak==1)/len(p_steak)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T11:00:39.353834Z","iopub.execute_input":"2021-10-18T11:00:39.354113Z","iopub.status.idle":"2021-10-18T11:00:39.362395Z","shell.execute_reply.started":"2021-10-18T11:00:39.354080Z","shell.execute_reply":"2021-10-18T11:00:39.361656Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}